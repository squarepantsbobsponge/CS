[TOC]

# 熵的定义：

熵：代表模型的混乱程度


$$
集合中含有较多类别时，熵越大\\
H(x)=-\sum_{i=1}^kp_ilogp_i\\
k为X的可取值类别数，p_i为取为x_i时候的概率
$$

# 条件熵的定义：

$$
H(Y|X):表示在随机变量X的条件下随机变量Y的不确定性，在给定X的条件下Y的条件概率分布对X的数学期望\\
H(Y|X)=\sum _{i=1}^k p_iH(Y|X=x_i)\\
p_i=P(X=x_i)
$$

# 划分选择:

## 信息增益：

$$
信息增益g(D,X):某特征X使得数据集D的不确定性减少程度\\
g(D,X)=H(D)-H(D|X)
$$

### 信息增益率：

背景：信息增益划分时，偏向于选择取值较多的特征
$$
信息增益率：g_R(D,X)={g(D,R) \over H_X(D)}\\
H_X(D)=-\sum_{i=1}^k{|Di|\over|D|}log{|Di|\over|D|} \quad |Di|为X=x_i时，包含个体数\\
当某特征值类别多时，每类的个体数少，H_X(D)大，信息增益率小
$$

## 基尼系数：

基尼系数：代表模型的不纯度，基尼系数越低，则特征越好
$$
设特征x_i有k个类别，第k个类别的概率是p_k\\
基尼系数：Gini(p)=\sum _{i=1}^k p_i(1-p_i)=1-\sum _{i=1}^kp_i^2\\
若对于数据集D，特征X的第k个类别的数量为C_k,则该数据集的基尼系数为\\
Gini(D)=1-\sum_{i=1}^k ({|C_k| \over |D|})^2
$$


![image-20240509160914436](C:\Users\丁晓琪\AppData\Roaming\Typora\typora-user-images\image-20240509160914436.png)

### 基尼增益：

$$
G(D,X)=Gini(D)-Gini(D,X)
$$

求解步骤：

![image-20240509161234981](C:\Users\丁晓琪\AppData\Roaming\Typora\typora-user-images\image-20240509161234981.png)

### 基尼增益率：

背景：存在偏向取值较多的特征的影响
$$
基尼增益率：
G_R(D,X)={G(D,X)\over |D_X|} \quad |D_X|其实就是D在基于X特征分类得到的类别数
$$
![image-20240509162128854](C:\Users\丁晓琪\AppData\Roaming\Typora\typora-user-images\image-20240509162128854.png)

# 连续值处理：

## 分区处理：

![image-20240509162308706](C:\Users\丁晓琪\AppData\Roaming\Typora\typora-user-images\image-20240509162308706.png)

## 中位点划分：

对原数据排序，再取任意相邻值的中位点为划分点，取信息熵最少的最优划分点